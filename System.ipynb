{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "import scipy.io as sio\n",
    "import collections\n",
    "import multiprocessing\n",
    "import itertools\n",
    "import networkx as nx\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def squared_distance_matrix(X, augmented=False):\n",
    "    \"\"\" Calculate the squared distance matrix for pointset X\n",
    "\n",
    "        X               M by n pointset, with M number of points and n the dimension\n",
    "        augmented       if True, the matrix will be augmented by a row and column of\n",
    "                        zeros to make room for extra entries\n",
    "\n",
    "        returns D, M by M array or (M+1) by (M+1) matrix\n",
    "\n",
    "    \"\"\"\n",
    "    XX = np.dot(X,X.T)\n",
    "    D = np.outer(np.diag(XX), np.ones(len(X)))-2*XX+np.outer(np.ones(len(X)),np.diag(XX))\n",
    "    if augmented == True:\n",
    "        n = len(D)\n",
    "        zeros_v = np.zeros((n,1))\n",
    "        zeros_h = np.zeros((1,n+1))\n",
    "        D = np.bmat('D zeros_v; zeros_h')\n",
    "    return D\n",
    "\n",
    "def interpolate_spline(y, N):\n",
    "    l = len(y)\n",
    "    x = np.linspace(0, l, l)\n",
    "    spline = interpolate.InterpolatedUnivariateSpline(x,y)\n",
    "    xnew = np.linspace(0, l, N*l)\n",
    "    ynew = spline(xnew)\n",
    "    return ynew\n",
    "    \n",
    "def local_max(x, threshold=1e-5):\n",
    "    \"\"\"\n",
    "        Get all local maxima of x by selecting all points which are \n",
    "        higher than its left and right neighbour\n",
    "    \"\"\"\n",
    "    maxima = np.r_[True, x[1:] > x[:-1]] & np.r_[x[:-1] > x[1:] , True]\n",
    "    # select all local maxima above the threshold\n",
    "    maxima_f = maxima & np.r_[x > threshold , True][:-1]\n",
    "    peak_indices =  np.where(maxima_f==True)[0]\n",
    "    return np.array(peak_indices)\n",
    " \n",
    "def direct_sound(x):\n",
    "    all_peak_indices = local_max(x,threshold=1e-5)\n",
    "    i = np.argsort(x[all_peak_indices])\n",
    "    direct_sound_index = all_peak_indices[i][-1]\n",
    "    peak_indices = all_peak_indices[np.where(all_peak_indices < direct_sound_index)[0]]\n",
    "    values = x[peak_indices]\n",
    "    # direct sound side lobe range\n",
    "    rng = direct_sound_index - max(peak_indices[np.where(values < (x[direct_sound_index] * 0.02))[0]])\n",
    "    return direct_sound_index, rng, all_peak_indices    \n",
    "\n",
    "def locate_source(p,d):\n",
    "    \"\"\" Locate source x using multilateration\n",
    "\n",
    "        p    sensors as a Mxn arraylike with M, number of sensors and n the dimension\n",
    "        d    distances from x to all sensors in d\n",
    "\n",
    "        returns x\n",
    "    \"\"\"\n",
    "    # M = sensors, n = dimensions\n",
    "    M, n = p.shape\n",
    "    p = np.matrix( p ).T\n",
    "\n",
    "    # pick closest receiver\n",
    "    c = np.argmin(d)\n",
    "    #sensors delta time relative to sensor c\n",
    "    d = d - min(d)\n",
    "\n",
    "    indices = list(range(M))\n",
    "    del indices[c]\n",
    "\n",
    "    A = np.zeros([M-2,n])\n",
    "    b = np.zeros([M-2,1])\n",
    "\n",
    "    i = indices[0]\n",
    "    for row,j in enumerate(indices[1:]):\n",
    "        A[row,:] = 2*( (d[j])*(p[:,i]-p[:,c]).T - (d[i])*(p[:,j]-p[:,c]).T )\n",
    "        b[row,0] = (d[i])*((d[j])**2-p[:,j].T*p[:,j]) + \\\n",
    "        ((d[i])-(d[j]))*p[:,c].T*p[:,c] + \\\n",
    "        (d[j])*(p[:,i].T*p[:,i]-(d[i])**2)\n",
    "\n",
    "\n",
    "    x = np.asarray( np.linalg.lstsq(A,b)[0] )[:,0]\n",
    "    return x\n",
    "\n",
    "class MeasurementData:\n",
    "    \n",
    "    def __init__(self, data, receivers, sources, room_dimensions, c=343, fs=96000):\n",
    "        \"\"\"\n",
    "        \n",
    "        Container class for measurement data and parameters\n",
    "        \n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.fs = fs\n",
    "        self.c = c\n",
    "        self.r = receivers\n",
    "        self.s = sources\n",
    "        self.L = room_dimensions\n",
    "        self.upsampling_rate = 1\n",
    "           \n",
    "    def crop(self, N):\n",
    "        self.data = self.data[:,:N]\n",
    "        \n",
    "    def interpolate(self, N):\n",
    "        self.upsampling_rate *= N\n",
    "        self.data = np.array([interpolate_spline(x,N) for x in self.data])\n",
    "      \n",
    "    def interpolate_parallel(self, N):\n",
    "        with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as pool:        \n",
    "            self.new_data = np.array(pool.starmap(interpolate_spline, zip(self.data, itertools.repeat(N))))\n",
    "            \n",
    "    def find_echoes(self, n=7, correct_offset=True):\n",
    "        echoes = np.zeros([len(self.data), n])\n",
    "        for j,rir in enumerate(self.data):\n",
    "            direct_sound_index, side_lobe_rng, all_peak_indices = direct_sound(rir)\n",
    "            N = direct_sound_index + side_lobe_rng\n",
    "            peak_indices = all_peak_indices[np.where(all_peak_indices > N)[0]]\n",
    "            i = np.argsort(rir[peak_indices])\n",
    "            sorted_peak_indices = peak_indices[i][::-1]\n",
    "            echoes[j,:] = np.r_[direct_sound_index, sorted_peak_indices[:(n-1)]]\n",
    "        \n",
    "        echoes = echoes * self.c / (self.upsampling_rate * self.fs)\n",
    "        if correct_offset == True:\n",
    "            offset = self._calculate_offset()\n",
    "            echoes += offset[:,np.newaxis]\n",
    "        return echoes\n",
    "            \n",
    "    def _calculate_offset(self):\n",
    "        direct_sound_distances = np.argmax(self.data, axis=1) * self.c / (self.upsampling_rate * self.fs)\n",
    "        source_est = np.array(locate_source(self.r, direct_sound_distances))\n",
    "        true_dist = np.linalg.norm(self.r - source_est, axis=1)\n",
    "        offset = true_dist - direct_sound_distances\n",
    "        return np.array(offset).T\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_sorting_indices(x, Y):\n",
    "    sort_i = np.zeros(len(x), dtype='int')\n",
    "    for i,el in enumerate(x):\n",
    "            sort_i[i] = np.where(el == Y)[0][0]\n",
    "    return sort_i\n",
    "\n",
    "def calc_rank(D, echo_set, t):\n",
    "        D[-1,0:-1] = np.array(echo_set).reshape(1,len(echo_set))**2\n",
    "        D[0:-1,-1] = np.array(echo_set).reshape(len(echo_set),1)**2\n",
    "        rank = np.linalg.matrix_rank(D, t)\n",
    "        return (rank, echo_set)\n",
    "\n",
    "class EchoData:\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def find_labels(self, D, threshold=0.045, verbose=False, parallel=False):\n",
    "        E = []\n",
    "        S = []\n",
    "        n = 6\n",
    "        if verbose==True:\n",
    "            print('Finding echo_set candidates per measurement ...')\n",
    "        S.append(self.data[:,0])\n",
    "        t = threshold\n",
    "        Ei = np.array([])\n",
    "        while len(Ei) < 1:\n",
    "            Ci = self._get_candidates(D, t=t, parallel=parallel)\n",
    "            if verbose == True:\n",
    "                print('prefilter threshold:', t)\n",
    "            t *= 2\n",
    "            if len(Ci) > 100 or t > 8*threshold:\n",
    "                break\n",
    "            Ei = self._get_unique_sets(Ci, n=n)\n",
    "        if 0 < len(Ei) < 20:\n",
    "            u = np.unique(Ci[:,0])\n",
    "            if len(u) >= n:\n",
    "                for ei in Ei:\n",
    "                    sort_i = find_sorting_indices(u, ei)\n",
    "                    ei_sorted = ei[sort_i]\n",
    "                    E.append(np.r_[self.data[:,0][np.newaxis,:], ei_sorted])\n",
    "        sys.stdout.flush()\n",
    "        if verbose==True:\n",
    "            print('Number of unique sets of',n,'echo_sets:',len(E))\n",
    "        return S,E\n",
    "\n",
    "\n",
    "    def _get_unique_sets(self, C, n=6):\n",
    "        G = nx.Graph()\n",
    "        edge_list = []\n",
    "        for i in range(len(C)):\n",
    "            G.add_node(i)\n",
    "            for j in range(i+1, len(C)):\n",
    "                if np.any(C[i] - C[j] == 0):\n",
    "                    edge_list.append((i,j))\n",
    "        G.add_edges_from(edge_list)\n",
    "        H = nx.complement(G)\n",
    "        cliques = nx.find_cliques(H)\n",
    "        return [C[l] for l in cliques if len(l) == n]\n",
    "\n",
    "    \n",
    "    def _get_candidates(self, D, t=0.0002, parallel=False):\n",
    "        \"\"\"\n",
    "        Filters out all non-feasible combinations of echoes based on the rank test of the augmented Euclidean Distance Matrix D.\n",
    "        If matrix D after augmenting with echo-data still passes the rank test, then the current set of echoes is saved.\n",
    "\n",
    "        D       Euclidean distance matrix of size (6,6)\n",
    "        t       rank test threshold\n",
    "\n",
    "        returns list of candidate echo sets\n",
    "        \"\"\"\n",
    "        \n",
    "        if parallel==True:\n",
    "            echo_sets = [echo_set for echo_set in itertools.product(*self.data[:,1:])]\n",
    "\n",
    "            with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as pool:\n",
    "                output = pool.starmap(calc_rank, zip(itertools.repeat(D), echo_sets, itertools.repeat(t)))\n",
    "\n",
    "            ranks, echo_sets = zip(*output)\n",
    "            candidates = [echo_set for rank, echo_set in output if rank < 6]            \n",
    "            #i = np.where(np.array(ranks) < 6)[0]\n",
    "            #candidates = np.array(echo_sets)[i]\n",
    "\n",
    "        else:\n",
    "            candidates = []\n",
    "            for echo_set in itertools.product(*self.data[:,1:]):\n",
    "                D[-1,0:-1] = np.array(echo_set).reshape(1,len(echo_set))**2\n",
    "                D[0:-1,-1] = np.array(echo_set).reshape(len(echo_set),1)**2\n",
    "                rank = np.linalg.matrix_rank(D, t)\n",
    "                if rank < 6:\n",
    "                    candidates.append(echo_set)\n",
    "        return np.array(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_sources_and_receivers(distance_data, dim):\n",
    "    # number of sources and receivers\n",
    "    M,N = distance_data.shape\n",
    "\n",
    "    # construct D matrix\n",
    "    D = distance_data**2\n",
    "\n",
    "    # reconstruct S and R matrix up to a transformation\n",
    "    U,si,V_h = np.linalg.svd(D)\n",
    "    R_hat = np.mat(U[:,:dim].T)\n",
    "    S_hat = np.mat(np.eye(dim)*si[:dim]) * np.mat(V_h[:dim,:])\n",
    "\n",
    "    hr = np.ones((1,N)) * np.linalg.pinv(S_hat)\n",
    "    I = np.eye(4)\n",
    "    zeros = np.zeros((4,1))\n",
    "    Hr = np.bmat('hr; zeros I')\n",
    "    R_hatHr = (R_hat.T * np.linalg.inv(Hr)).H\n",
    "\n",
    "    hs = np.linalg.pinv(R_hatHr).H * np.ones((M,1))\n",
    "    zeros = np.zeros((1,4))\n",
    "    Hs = np.bmat('I; zeros')\n",
    "    Hs = np.linalg.inv(np.bmat('Hs hs'))\n",
    "\n",
    "    S_prime = Hs*Hr*S_hat\n",
    "\n",
    "    A = np.array(S_prime[4,:])\n",
    "    XYZ = np.array(S_prime[1:4,:])\n",
    "    X = np.array(S_prime[1,:])\n",
    "    Y = np.array(S_prime[2,:])\n",
    "    Z = np.array(S_prime[3,:])\n",
    "\n",
    "    qq = np.vstack( (np.ones((1,N)), 2*XYZ, XYZ**2, 2*X*Y, 2*X*Z, 2*Y*Z) ).T\n",
    "    q = np.linalg.pinv(qq).dot(A.T)\n",
    "    Q = np.vstack( (np.hstack( (np.squeeze(q[:4].T), -0.5) ), np.hstack([q[1], q[4], q[7], q[8], 0]), np.hstack([q[2], q[7], q[5], q[9], 0]), np.hstack([q[3],q[8],q[9],q[6],0]), np.array([-0.5,0,0,0,0]) ) )\n",
    "\n",
    "    if np.all(np.linalg.eigvals(Q[1:4,1:4]) > 0):\n",
    "        C = np.linalg.cholesky(Q[1:4,1:4]).T\n",
    "    else:\n",
    "        C = np.eye(3)\n",
    "\n",
    "    Hq = np.vstack((  np.array([1,0,0,0,0]),\n",
    "                      np.hstack( (np.zeros((3,1)), C, np.zeros((3,1)))),\n",
    "                      np.hstack( (-q[0], -2*np.squeeze(q[1:4].T), 1))\n",
    "                    ))\n",
    "\n",
    "    H = np.mat(Hq) * Hs * Hr\n",
    "    Se = (H*S_hat)[1:4,:]\n",
    "    Re = 0.5 * (np.linalg.inv(H).H*R_hat)[1:4,:]\n",
    "\n",
    "    return Re, Se\n",
    "\n",
    "\n",
    "def rigid_transform_3D(A, B):\n",
    "    assert len(A) == len(B)\n",
    "\n",
    "    N = A.shape[0]; # total points\n",
    "\n",
    "    centroid_A = np.mean(A, axis=0)\n",
    "    centroid_B = np.mean(B, axis=0)\n",
    "\n",
    "    # centre the points\n",
    "    AA = A - np.tile(centroid_A, (N, 1))\n",
    "    BB = B - np.tile(centroid_B, (N, 1))\n",
    "\n",
    "    H = np.transpose(AA) * BB\n",
    "\n",
    "    U, S, Vt = np.linalg.svd(H)\n",
    "\n",
    "    R = Vt.T * U.T\n",
    "\n",
    "    # special reflection case\n",
    "    if np.linalg.det(R) < 0:\n",
    "        R = Vt.T * U.T\n",
    "\n",
    "    t = -R*centroid_A.T + centroid_B.T\n",
    "\n",
    "\n",
    "    return R, t\n",
    "\n",
    "def pair_iterator(list_of_lists):\n",
    "    copy_list_of_lists = list(list_of_lists)\n",
    "    for set1 in reversed(list_of_lists):\n",
    "        copy_list_of_lists.pop()\n",
    "        for set2 in copy_list_of_lists:\n",
    "            for pair in itertools.product(set1,set2):\n",
    "                yield pair\n",
    "\n",
    "class DistanceData:\n",
    "    \n",
    "    def __init__(self, S, E):\n",
    "        self.S = S\n",
    "        self.E = E\n",
    "\n",
    "    def find_images(self, r):\n",
    "        results = {}\n",
    "        for (E0, E1) in pair_iterator(self.E):\n",
    "            data_hat = np.hstack( (np.array(self.S).T,(E0[1:,:]).T ,(E1[1:,:]).T) )\n",
    "            error_r, s_est = self._compute_coordinates(data_hat, r)\n",
    "            results[error_r] = (s_est, (E0, E1))\n",
    "        return results\n",
    "\n",
    "    def _compute_coordinates(self, data, r):\n",
    "        \"\"\"\n",
    "        Test whether the input data can be used for localization of sources.\n",
    "\n",
    "        data    distance data between N sources and M known receivers\n",
    "        r       coordinates of M receivers\n",
    "\n",
    "        returns (valid,r_est)\n",
    "\n",
    "            valid   if True, r_est and s_est are correct estimations\n",
    "            r_est   estimation of receiver locations\n",
    "        \"\"\"\n",
    "        M, N = data.shape\n",
    "        Re, Se = compute_sources_and_receivers(data, 5)\n",
    "        # find transformation between R and Re\n",
    "        R_r,t_r = rigid_transform_3D(np.mat(Re.T), np.mat(r))\n",
    "        # find transformation between R and Re\n",
    "        #Apply transformation on Re and Se to obtain estimated locations of sources\n",
    "        r_est = np.array(R_r*np.mat(Re) + np.tile(t_r, (1,M)))\n",
    "        s_est = np.array((-1*R_r)*np.mat(Se) + np.tile(t_r, (1,N)))\n",
    "\n",
    "        error_r = np.linalg.norm(r_est.T - r, ord='fro') / np.sqrt(M)\n",
    "\n",
    "        return error_r, s_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Line:\n",
    "\n",
    "    def __init__(self, a,b,c):\n",
    "        \"\"\" standard form a*x + b*y = c\"\"\"\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.c = c\n",
    "\n",
    "    def get_x(self,y):\n",
    "        x = (-self.c - self.b*y) / float(self.a)\n",
    "        return x\n",
    "\n",
    "    def get_y(self,x):\n",
    "        y = (-self.c - self.a*x) / float(self.b)\n",
    "        return x\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.a) +'x + ' + str(self.b) + 'y = ' + str(self.c)\n",
    "    \n",
    "def intersections(lines):\n",
    "    intersections = []\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        for j in range(i+1, len(lines)):\n",
    "            point = intersect(lines[i],lines[j])\n",
    "            if point:\n",
    "                intersections.append(point)\n",
    "    return intersections\n",
    "\n",
    "def intersect(l1, l2):\n",
    "    detA = (l1.a*l2.b - l1.b*l2.a)\n",
    "    if not detA == 0:\n",
    "        x = (l1.c*l2.b - l1.b*l2.c) /  detA\n",
    "        y = (l1.a*l2.c - l1.c*l2.a) /  detA\n",
    "        return x,y\n",
    "    return None\n",
    "\n",
    "def line_from_points(p1,p2):\n",
    "    x1,y1,z1 = p1\n",
    "    x2,y2,z2 = p2\n",
    "    a = y1-y2\n",
    "    b = x2-x1\n",
    "    c = (x1-x2)*y1 + (y2-y1)*x1\n",
    "    return Line(a,b,-c)\n",
    "\n",
    "class ImageSourceData:\n",
    "    \n",
    "    def __init__(self, data, N, r, room_dimensions):\n",
    "        self.data = data\n",
    "        self.N = N\n",
    "        self.r = r\n",
    "        self.L = room_dimensions\n",
    "        self.images = None\n",
    "        self.sources = None\n",
    "        self.midpoints = None\n",
    "        self.normals = None\n",
    "        self.wallpoints = None\n",
    "        self.vertices = None\n",
    "        \n",
    "    def find_walls(self, threshold, bestN):\n",
    "        wall_points = self._calculate_wall_points(self.N, threshold=threshold, bestN=bestN)\n",
    "        todel = []\n",
    "        for i,wset in enumerate(wall_points):\n",
    "            if np.any(np.array(wset)[:,2] > (self.L[2]-0.5)):\n",
    "                todel.append(int(i))\n",
    "            elif np.any(np.array(wset)[:,2] < 0.5):\n",
    "                todel.append(int(i))\n",
    "        self.wallpoints = np.delete(np.array(wall_points), np.array(todel, dtype='int'), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        self.vertices = self._calculate_vertices2D(self.wallpoints)\n",
    "        return self.wallpoints, self.vertices\n",
    "        \n",
    "    def _calculate_wall_points(self, N, threshold=0.05, bestN=5):\n",
    "        \"\"\"\n",
    "            \n",
    "        N            number of sources\n",
    "        threshold    data filter\n",
    "        bestN        Only use bestN results\n",
    "        \n",
    "        \"\"\"\n",
    "        X = self.data\n",
    "        self.sources = []\n",
    "        self.midpoints = []\n",
    "        self.normals = []\n",
    "        self.images = []\n",
    "        keys = [k for k in sorted(X) if k < threshold][:bestN]\n",
    "        for k in keys:\n",
    "            data, distance_data = X[k]\n",
    "            for j,e in enumerate(distance_data):\n",
    "                source = locate_source(self.r, e[0,:])\n",
    "                #i = e.measurement.index\n",
    "                #source = data[:,i]\n",
    "                est_images = (data[:,(N+j*6):(N+(j+1)*6)]).T\n",
    "                mid_points = (est_images + source) / 2.0\n",
    "                normal = source - est_images\n",
    "                unit_normal = normal / np.linalg.norm(normal, axis=1).reshape(len(normal),1)\n",
    "                self.images.append(est_images)\n",
    "                self.normals.append(unit_normal)\n",
    "                self.midpoints.append(mid_points)\n",
    "                self.sources.append(source)\n",
    "\n",
    "        sets = [[p] for p in self.midpoints[0]]\n",
    "        for i,normal in enumerate(self.normals[0]):\n",
    "            for k,normal_set in enumerate(self.normals[1:]):\n",
    "                for j,other_normal in enumerate(normal_set):\n",
    "                    if 0.9 < normal.dot(other_normal) < 1.1:\n",
    "                        sets[i].append(self.midpoints[k+1][j])\n",
    "        return sets\n",
    "\n",
    "\n",
    "\n",
    "    def _calculate_vertices2D(self, wall_points):\n",
    "        lines = []\n",
    "        res_A = []\n",
    "        res_B = []\n",
    "        f_A = []\n",
    "        f_B = []\n",
    "        for i in range(len(wall_points)):\n",
    "            data = np.vstack(wall_points[i])\n",
    "            if len(data) > 2:\n",
    "                x = data[:,0]\n",
    "                y = data[:,1]\n",
    "                fit_A, residuals_A, rank, singular_values, rcond = np.polyfit(x, y, 1, full=True)\n",
    "                fit_B, residuals_B, rank, singular_values, rcond = np.polyfit(y, x, 1, full=True)\n",
    "                f_A.append(fit_A)\n",
    "                f_B.append(fit_B)\n",
    "                res_A.append(residuals_A)\n",
    "                res_B.append(residuals_B)\n",
    "            elif len(data) == 2:\n",
    "                if not (abs(data[0][2] - data[1][2]) < 0.1 and (abs(data[0][1] - data[1][1]) > 0.1 or abs(data[0][0] - data[1][0]) > 0.1)):\n",
    "                    lines.append(line_from_points(data[0], data[1]))\n",
    "\n",
    "\n",
    "        if len(res_A) > 0:\n",
    "\n",
    "            f_A = np.array(f_A)\n",
    "            f_B = np.array(f_B)\n",
    "            res_A = np.array(res_A)\n",
    "            res_B = np.array(res_B)\n",
    "\n",
    "            favorA = res_A < res_B\n",
    "\n",
    "            for f in f_A[(favorA).ravel()]:\n",
    "                #y = mx+c\n",
    "                m,c = f\n",
    "                lines.append(Line(-m, 1, c))\n",
    "\n",
    "            for f in f_B[(~favorA).ravel()]:\n",
    "                # x = ny+d\n",
    "                n,d = f\n",
    "                lines.append(Line(1, -n, d))\n",
    "\n",
    "        intersects = np.array([i for i in intersections(lines) if np.all(np.abs(np.array(i)) < 100)])\n",
    "        return intersects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# choose dataset\n",
    "fname = 'datasets/set_1.mat'\n",
    "dataset = sio.loadmat(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fs = float(dataset['fs'])\n",
    "M = int(dataset['M'])\n",
    "N = int(dataset['N'])\n",
    "h = float(dataset['h'])\n",
    "l = float(dataset['l'])\n",
    "w = float(dataset['w'])\n",
    "r = dataset['receivers']\n",
    "s = dataset['sources']\n",
    "data = dataset['data'].T\n",
    "c = float(dataset['c'])\n",
    "\n",
    "maxsize = np.sqrt(w**2+l**2+h**2) #m\n",
    "max_delay = maxsize / float(c) \n",
    "maxlength = int(2 * max_delay * fs)\n",
    "\n",
    "measurements  = [MeasurementData(data=np.hstack(source_data).T, \n",
    "                                 receivers=r, \n",
    "                                 sources=s[i], \n",
    "                                 room_dimensions=(w,l,h), \n",
    "                                 c=c, \n",
    "                                 fs=fs) \n",
    "                 for i,source_data in enumerate(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[m.crop(maxlength) for m in measurements]\n",
    "[m.interpolate(10) for m in measurements]\n",
    "echo_data = [EchoData(m.find_echoes()) for m in measurements]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D = squared_distance_matrix(r, augmented=True)\n",
    "S, E = zip(*[e.find_labels(D,threshold=0.005, parallel=True) for e in echo_data[:6]])\n",
    "E = [e for e in E if len(e) > 0]\n",
    "S = np.vstack(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ddata = DistanceData(S,E)\n",
    "results = ddata.find_images(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.69078664,  2.90883527,  1.48490892,  2.33221656,  1.75253437],\n",
       "       [ 4.46188143,  4.99649048,  4.93920476,  6.02732698,  5.84066562],\n",
       "       [ 4.68590331,  6.8951384 ,  6.39338184,  5.47531135,  6.08648228],\n",
       "       [ 4.73699601,  4.65849256,  3.5396933 ,  3.36478948,  2.97840207],\n",
       "       [ 5.18682622,  5.44846444,  3.17632767,  5.17625823,  4.42829166],\n",
       "       [ 5.43157101,  5.17870923,  7.34770788,  4.84433427,  5.75848853],\n",
       "       [ 6.52774185,  4.40159986,  3.67760788,  5.5632051 ,  4.37148228]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x112445748>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAEACAYAAABBDJb9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f4b7128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imagedata = ImageSourceData(results, 6, r, (w,l,h))\n",
    "wall_points,vertices = imagedata.find_walls(threshold=0.05, bestN=5)\n",
    "im = np.vstack(imagedata.images)\n",
    "plt.scatter(im[:,0], im[:,1])\n",
    "wp = np.vstack(wall_points)\n",
    "plt.scatter(wp[:,0], wp[:,1], color=(1,0,0,1))\n",
    "plt.scatter(vertices[:,0], vertices[:,1], color=(0,1,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
